[train_data]
class=dataset.load_dataset_from_files
s_source="/net/work/people/mediankin/snmt/data/czeng/pilot/train/cz_lin.txt.gz"
s_target="/net/work/people/mediankin/snmt/data/czeng/pilot/train/en.txt.gz"
preprocessors=[("source", "source_bpe", <bpe_preprocess>), ("target", "target_bpe", <bpe_preprocess>)]

[val_data]
class=dataset.load_dataset_from_files
s_source="/net/work/people/mediankin/snmt/data/czeng/pilot/dev/cz_lin.txt.gz"
s_target="/net/work/people/mediankin/snmt/data/czeng/pilot/dev/en.txt.gz"
preprocessors=[("source", "source_bpe", <bpe_preprocess>), ("target", "target_bpe", <bpe_preprocess>)]

[bpe_preprocess]
class=processors.bpe.BPEPreprocessor
merge_file="/net/work/people/mediankin/snmt/data/czeng/pilot/merge_file.bpe"

[bpe_postprocess]
class=processors.bpe.BPEPostprocessor

[shared_vocabulary]
class=vocabulary.from_bpe
path="/net/work/people/mediankin/snmt/data/czeng/pilot/merge_file.bpe"

[encoder]
class=encoders.recurrent.SentenceEncoder
name="sentence_encoder"
rnn_size=300
max_input_len=50
embedding_size=300
dropout_keep_prob=0.8
data_id="source_bpe"
vocabulary=<shared_vocabulary>

[attention]
class=attention.Attention
name="att_sent_enc"
encoder=<encoder>
state_size=300
dropout_keep_prob=0.8

[decoder]
class=decoders.decoder.Decoder
name="decoder"
encoders=[<encoder>]
attentions=[<attention>]
rnn_size=256
embedding_size=300
dropout_keep_prob=0.8
data_id="target_bpe"
vocabulary=<shared_vocabulary>
max_output_len=50

[trainer]
class=trainers.cross_entropy_trainer.CrossEntropyTrainer
decoders=[<decoder>]
l2_weight=1.0e-8

[runner]
class=runners.runner.GreedyRunner
decoder=<decoder>
output_series="series_named_greedy"
postprocess=<bpe_postprocess>

[bleu]
class=evaluators.bleu.BLEUEvaluator
name="BLEU-4"

[tf_manager]
class=tf_manager.TensorFlowManager
num_threads=4
num_sessions=1
minimize_metric=False
save_n_best=3

[main]
name="baseline"
output="/net/work/people/mediankin/snmt/experiments/pilot/baseline"
runners=[<runner>]
tf_manager=<tf_manager>
trainer=<trainer>
train_dataset=<train_data>
val_dataset=<val_data>
evaluation=[("series_named_greedy", "target", <bleu>), ("series_named_greedy", "target", evaluators.ter.TER)]
batch_size=80
runners_batch_size=256
epochs=10
validation_period=5000
logging_period=80
